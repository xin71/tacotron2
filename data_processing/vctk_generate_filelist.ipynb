{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data 44257\n",
      "length of txt data 44085\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import random \n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = '/data3/VCTK_spec/VCTK-Corpus/wav48'\n",
    "TXT_PATH = '/data3/VCTK/VCTK-Corpus/txt'\n",
    "COMMON_TXT_PATH = '/data3/VCTK/VCTK-Corpus/txt'\n",
    "ALL_DATA_PATH = sorted(glob.glob(os.path.join(DATA_PATH, '*/*.npy')))\n",
    "ALL_TXT_PATH = sorted(glob.glob(os.path.join(TXT_PATH, '*/*.txt')))\n",
    "SR = 16000\n",
    "CUT = 12\n",
    "\n",
    "print('length of data', len(ALL_DATA_PATH))\n",
    "print('length of txt data', len(ALL_TXT_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add files to the train list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_text(path):\n",
    "    with open(path, 'r') as f:\n",
    "        line = f.readline()\n",
    "        if '\\n' in line:\n",
    "            return line\n",
    "        else:\n",
    "            line = line + '\\n'\n",
    "            return line\n",
    "\n",
    "    \n",
    "def check_audio_length(path):\n",
    "    audio, _ = sf.read(path)\n",
    "    if len(audio) < (CUT * SR):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def check_np_length(path):\n",
    "    data = np.load(path)\n",
    "    _, length = data.shape\n",
    "    \n",
    "    if int(length * 200) < (CUT * SR):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def random_sample(used_path, all_path):\n",
    "    all_path.remove(used_path)\n",
    "    path = random.sample(all_path, 1)[0]\n",
    "    while True:\n",
    "        if check_np_length(path) == False:\n",
    "            path = random.sample(all_path, 1)[0]\n",
    "        else:\n",
    "            return path\n",
    "        \n",
    "def check_same(data_path, txt_path):\n",
    "    print(data_path)\n",
    "    data_id = data_path.split('/')[-1].split('.')[0]\n",
    "    print(data_id)\n",
    "    txt_id = txt_path.split('/')[-1].split('.')[0]\n",
    "    print(txt_id)\n",
    "    if data_id == txt_id:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def convert_to_txt_path(data_path):\n",
    "    \n",
    "    data_id = data_path.split('/')[-1].split('.')[0]\n",
    "    p_id = data_id.split('_')[0]\n",
    "    txt_path = os.path.join(COMMON_TXT_PATH, p_id, data_id+'.txt')\n",
    "    return txt_path    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_pid ['p264', 'p275', 'p336', 'p252', 'p304', 'p316', 'p339', 'p360', 'p265', 'p330', 'p293', 'p285', 'p305', 'p226', 'p236', 'p269', 'p281', 'p283', 'p351', 'p276', 'p376', 'p312', 'p287', 'p335', 'p261', 'p298', 'p254', 'p310', 'p306', 'p237', 'p240', 'p239', 'p300', 'p241', 'p247', 'p256', 'p229', 'p255', 'p334', 'p271', 'p263', 'p279', 'p243', 'p333', 'p288', 'p253', 'p244', 'p248', 'p329', 'p238', 'p301', 'p272', 'p374', 'p277', 'p361', 'p323', 'p234', 'p246', 'p347', 'p260', 'p231', 'p295', 'p262', 'p273', 'p308', 'p228', 'p250', 'p259', 'p307', 'p232', 'p314', 'p294', 'p317', 'p284', 'p266', 'p267', 'p292', 'p362', 'p230', 'p245', 'p345', 'p343', 'p225', 'p233', 'p258']\n",
      "ts pid ['p364', 'p251', 'p280', 'p341', 'p270', 'p326', 'p303', 'p311', 'p257', 'p363', 'p249', 'p297', 'p313', 'p282', 'p278', 'p302', 'p299', 'p268', 'p318', 'p286', 'p227', 'p274', 'p340']\n"
     ]
    }
   ],
   "source": [
    "all_pid = [ x.split('/')[-1] for x in glob.glob(COMMON_TXT_PATH + '/*')]\n",
    "tr_pid = all_pid[:85]\n",
    "ts_pid = all_pid[85:]\n",
    "print('tr_pid', tr_pid)\n",
    "print('ts pid', ts_pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/xliu0/workspace/tacotron2/filelists/train_filelist_vctk.txt'\n",
    "test_path = '/home/xliu0/workspace/tacotron2/filelists/test_filelist_vctk.txt'\n",
    "\n",
    "train_path_alt = '/home/xliu0/workspace/tacotron2/filelists/train_filelist_vctk_alt.txt'\n",
    "test_path_alt = '/home/xliu0/workspace/tacotron2/filelists/test_filelist_vctk_alt.txt'\n",
    "\n",
    "\n",
    "for data_path in ALL_DATA_PATH:\n",
    "    if data_path.split('/')[-2] in tr_pid:\n",
    "        if check_np_length(data_path) == False:\n",
    "            continue\n",
    "        txt_path = convert_to_txt_path(data_path)\n",
    "        if os.path.exists(txt_path) == False:\n",
    "            continue\n",
    "        else:\n",
    "            with open(train_path, 'a') as f1, open(train_path_alt, 'a') as f2:\n",
    "            # Write into train file:\n",
    "                s1 = data_path + '|' + read_text(txt_path)\n",
    "                f1.write(s1)\n",
    "                # Write into alt file \n",
    "                data_folder_path = data_path.split('/')[:-1]\n",
    "                data_folder_path = '/'.join(data_folder_path)\n",
    "                all_wav_data_folder = sorted(glob.glob(data_folder_path + '/*.npy'))\n",
    "                alt_wav_path = random_sample(data_path, all_wav_data_folder)\n",
    "                alt_txt_path = convert_to_txt_path(alt_wav_path)\n",
    "                s2 = alt_wav_path + '|' + read_text(alt_txt_path)\n",
    "                f2.write(s2)\n",
    "    elif data_path.split('/')[-2] in ts_pid:\n",
    "        if check_np_length(data_path) == False:\n",
    "            continue\n",
    "        txt_path = convert_to_txt_path(data_path)\n",
    "        if os.path.exists(txt_path) == False:\n",
    "            continue\n",
    "        else:\n",
    "            with open(test_path, 'a') as f1, open(test_path_alt, 'a') as f2:\n",
    "            # Write into train file:\n",
    "                s1 = data_path + '|' + read_text(txt_path)\n",
    "                f1.write(s1)\n",
    "                # Write into alt file \n",
    "                data_folder_path = data_path.split('/')[:-1]\n",
    "                data_folder_path = '/'.join(data_folder_path)\n",
    "                all_wav_data_folder = sorted(glob.glob(data_folder_path + '/*.npy'))\n",
    "                alt_wav_path = random_sample(data_path, all_wav_data_folder)\n",
    "                alt_txt_path = convert_to_txt_path(alt_wav_path)\n",
    "                s2 = alt_wav_path + '|' + read_text(alt_txt_path)\n",
    "                f2.write(s2)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taco",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
